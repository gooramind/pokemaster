---
theme: uncover # 또는 gaia, default 등 원하시는 테마
size: 16:9
paginate: true # 페이지 번호 표시
header: '포켓 마스터: 부분 이미지 포켓몬 분류기'
footer: 'GitHub ID / 이름'
---

# **포켓 마스터**
## 일부만 보고도 무슨 포켓몬인지 알아 맞추는 인공지능 모델

발표자: (사용자님 성함/아이디)
날짜: (발표 날짜)

---

## **프로젝트 개요**

* **목표:** 포켓몬 사진의 일부만 보고도 어떤 포켓몬인지 맞추는 딥러닝 모델 개발
* **핵심 기술:** 합성곱 신경망 (CNN)
* **주요 과정:** 데이터 준비 → 모델 설계 → 학습 → 평가 → 예측
* **최종 결과물:** 학습된 모델 및 예측 결과, 그리고 이 발표 자료!

---

## **1. 프로젝트 준비**
> 개발 환경 설정 및 데이터셋 확보

* **개발 환경:**
    * `PokemonProject` 폴더 생성
    * 가상 환경(`venv`) 구성
    * 필수 라이브러리 설치: TensorFlow, OpenCV, NumPy, Matplotlib, Scikit-learn
* **데이터셋:**
    * Kaggle의 "1세대 포켓몬 이미지" 데이터셋 사용
        * [https://www.kaggle.com/datasets/mikoajkolman/pokemon-images-first-generation17000-files](https://www.kaggle.com/datasets/mikoajkolman/pokemon-images-first-generation17000-files)
    * `PokemonProject/dataset/` 경로에 포켓몬별 폴더로 정리

---

## **2. 데이터 탐색 및 전처리**
> 모델이 학습할 수 있는 형태로 데이터 가공

* **데이터 탐색 (EDA):**
    * 각 포켓몬 클래스 및 이미지 수 확인 (초기 143종)
    * 샘플 이미지 시각화
* **이미지 전처리:**
    * 이미지 크기 통일 (예: 128x128 픽셀)
    * 픽셀 값 0~1 사이로 정규화
* **레이블 처리:**
    * 포켓몬 이름(문자열)을 숫자 인덱스로 변환
    * 원-핫 인코딩 적용
* **데이터셋 분할:** 학습용 / 검증(테스트)용 데이터 분리 (예: 80:20 비율)

---

## **3. 딥러닝 모델 개발 (CNN)**
> 이미지 특징 추출 및 분류를 위한 모델 설계

* **모델 구조:**
    * 입력층 (`Input`)
    * 합성곱층 (`Conv2D`)과 풀링층 (`MaxPooling2D`) 반복 (특징 추출)
    * 데이터 증강 레이어 (`RandomFlip`, `RandomRotation`, `RandomZoom`) 추가 (과적합 방지)
    * 드롭아웃 (`Dropout`) 적용 (과적합 방지)
    * Flatten층
    * 완전 연결층 (`Dense`)
    * 출력층 (`Dense` + `softmax` 활성화 함수)
* **컴파일:**
    * Optimizer: `adam`
    * Loss function: `categorical_crossentropy`
    * Metrics: `accuracy`

---

## **4. 모델 학습 및 평가 과정 (시도와 개선)**

> ### **1차 시도: 143종 전체 포켓몬 학습**
>
> * **문제점 발견:**
>     * 학습을 진행해도 검증 정확도가 특정 수준 이상 오르지 않고 정체 (예: ~66%)
>     * **과적합 (Overfitting)** 발생: 훈련 데이터에 대해서는 성능이 좋지만, 새로운 데이터(검증 데이터)에 대해서는 성능이 낮음
> * **원인 분석:**
>     * 분류해야 할 클래스(143종)가 너무 많음
>     * 클래스별 이미지 수가 상대적으로 부족하여 모델이 충분한 특징을 학습하기 어려움
>     * 데이터셋 내 이미지 품질의 불균일 가능성

---

## **4. 모델 학습 및 평가 과정 (시도와 개선)**

> ### **2차 시도: 학습 대상 축소 (10종) 및 데이터 증강**
>
> * **해결 전략:**
>     1.  학습 대상을 **특징이 뚜렷한 10종의 포켓몬으로 축소**
>         * 선정된 포켓몬: Pikachu, Bulbasaur, Charmander, Pidgeot, Meowth, Magikarp, Snorlax, Gengar, Caterpie, Voltorb
>     2.  에포크 수를 줄여서(예: 10~20) 빠르게 결과 확인
>     3.  **데이터 증강 (Data Augmentation)** 적용: 제한된 데이터를 실시간으로 변형시켜 학습 데이터 양을 늘리고 다양성 확보
>         * 적용 기법: 좌우 반전, 회전, 확대/축소 등
> * **결과:**
>     * 검증 정확도 크게 향상! (예: 약 66% → **90% 이상으로 상승**)
>     * 하지만 여전히 약간의 과적합 경향 관찰됨 [(uploaded:image_cdeb1a.png-a51e8c07-39e3-472e-a67a-ba27a8e47ead)]

---
## **4. 모델 학습 및 평가 과정 (시도와 개선)**

> ### **3차 시도 (현재 및 향후 계획): 추가 개선**
>
> * **현재 상태:** 10종 포켓몬, 데이터 증강 적용, 20 에포크 학습 후 검증 정확도 약 92% 달성. 과적합은 이전보다 완화되었으나 여전히 존재.
> * **추가 개선 방안 논의:**
>     * 드롭아웃 비율 조절
>     * 조기 종료(Early Stopping) 적용
>     * 가중치 규제(Weight Regularization)
>     * **앙상블(Ensemble) 기법 도입 고려** (현재 가장 관심 있는 부분)
> * **클래스-인덱스 매핑 오류 점검:** `LabelEncoder` 대신 직접 인덱스 매핑으로 변경하여 레이블 순서 꼬임 방지.

---

## **5. 모델 저장 및 예측**

* **모델 저장:** 학습된 최적의 모델을 `.keras` 파일로 저장 (예: `models/pokemon_classifier_10_species_final.keras`)
* **예측 함수 구현:**
    * 저장된 모델과 `index_to_class` 매핑을 불러옴
    * 입력 이미지를 모델이 학습한 형태로 전처리 (크기 조절, 정규화)
    * 예측 수행 및 가장 확률 높은 클래스 이름과 확신도 출력
    * Matplotlib을 이용한 한글 폰트 처리 및 결과 시각화
* **(프로젝트 목표) 부분 이미지 예측:** 현재 예측 함수는 전체 이미지를 대상으로 하지만, 함수 내 이미지 전처리 부분에 "이미지 자르기(crop)" 로직을 추가하면 부분 이미지 예측도 가능.

---

## **6. 결과 및 결론**

* **주요 성과:**
    * 10종의 포켓몬에 대해 데이터 증강을 적용하여 약 **92%**의 검증 정확도를 달성.
    * 과적합 문제를 인지하고, 이를 해결하기 위한 다양한 전략을 모색하고 적용함.
    * 데이터 전처리부터 모델 학습, 평가, 예측에 이르는 전체 딥러닝 파이프라인을 직접 구축.
* **한계점 및 향후 개선 방향:**
    * 현재 모델은 여전히 약간의 과적합 경향을 보임 → 드롭아웃, 조기 종료 등 추가 적용 필요.
    * 더 많은 포켓몬 종류를 높은 정확도로 분류하기 위해서는 전이 학습(Transfer Learning)과 같은 고급 기법 도입 고려.
    * 부분 이미지 예측 기능의 고도화.
* **배운 점:** (여기에 사용자님이 프로젝트를 통해 배운 점이나 느낀 점을 자유롭게 적어주세요!)

---

## **Q & A**

감사합니다!
