#  포켓 마스터 
> ## 일부만 보고도 무슨 포켓몬인지 알아 맞추는 인공지능 모델

---

### 프로젝트 목표

이 프로젝트는 포켓몬 사진의 일부만 보고도 어떤 포켓몬인지 맞추는 인공지능 모델을 개발하는 과정을 다룹니다. 

###  개발 과정
1세대 포켓몬 이미지 데이터를 **'합성곱 신경망(CNN)'** 이라는 딥러닝 모델에 학습시켰습니다. 

###  최종 결과
최종 목표는 불완전한 이미지를 제시했을 때도 인공지능이 포켓몬을 얼마나 정확하게 구별하는지 성능을 확인하고, 그 과정을 기록하는 것입니다.

#  포켓 마스터: 부분 이미지 포켓몬 분류기

> ## 일부만 보고도 무슨 포켓몬인지 알아 맞추는 인공지능 모델

<br>

##  프로젝트 목차

### 1. 프로젝트 준비 (Preparation)
   1.1. **개발 환경 설정**: 가상 환경 생성 및 라이브러리 설치
   1.2. **데이터셋 준비**: 데이터 다운로드 및 폴더 

### 2. 데이터 탐색 및 전처리 (Data Exploration & Preprocessing)
   2.1. **데이터 탐색(EDA)**: 클래스 및 샘플 이미지 확인
   2.2. **이미지 전처리**: 이미지 크기 통일 및 픽셀 정규화
   2.3. **레이블 처리**: 포켓몬 이름을 숫자 레이블로 변환 (원-핫 인코딩)
   2.4. **데이터셋 분할**: 학습, 검증, 테스트용으로 데이터 분리

### 3. 딥러닝 모델 개발 (Model Development)
   3.1. **CNN 모델 설계**: `Conv2D`, `Dense` 등을 이용한 신경망 구성
   3.2. **모델 컴파일**: Optimizer, Loss, Metrics 설정
   3.3. **모델 학습**: `fit()` 함수로 훈련 및 과정 시각화
   3.4. **모델 저장**: 학습된 모델 가중치를 파일로 저장

### 4. 모델 성능 평가 (Model Evaluation)
   4.1. **테스트 데이터셋 평가**: 최종 모델 성능 측정
   4.2. **결과 분석**: 혼동 행렬 등으로 예측 오류 분석

### 5. 부분 이미지를 이용한 추론 (Inference with Partial Images)
   5.1. **추론 함수 개발**: 이미지 자르기/가리기 기능 구현
   5.2. **예측 및 테스트**: 부분 이미지로 포켓몬 이름 예측

### 6. 프로젝트 문서화 (Documentation)
   6.1. **`README.md` 작성**: 프로젝트 전 과정 요약 및 기록
   6.2. **`requirements.txt` 생성**: 설치 라이브러리 목록 저장
   
<br>
## 1. 프로젝트 시작
> ## 1.1 개발 환경 설정
### pokemoneProject 폴더 생성
### venv라는 가상환경을 만듬
### tensorflow / opencv-python / numpy / matplotlib 총 4개의 라이브러리 다운로드

> ## 1.2 데이터셋 준비
### 캐글에서 데이터 라벨링이 되어있는 데이터들을 다운받
> ### https://www.kaggle.com/datasets/mikoajkolman/pokemon-images-first-generation17000-files?resource=download
### PokemonProject 폴더안에 dataset이라는 하위 폴더를 생성
### 다운로드한 데이터셋 파일들을 dataset 폴더안으로 옮김
### 가상환경을 만들고, 주피터 노트북을 실행
### 데이터의 사이즈를 조정하고 이름을 숫자로 변경

>##1트: 
###문제 정의: 1트 ~ 왜 안됐을까?? "과적합(overfitting)"
###-> 학습 수를 늘려도, 더이상 효율이 안나오는 상태
###-> 예) 수능을 1년 2년 3년 ... n년을 한다고 해도 점수 가 더 안오름

>##과적합이 발생한 문제점 파악: 
###143종이 너무 많다.,
###클래스별 이미지 수가 적다.,
###이미지 퀄리티가 떨어질 수 있다.,

>##해결책: 
###10종만 뽑아서 학습시킨다.,
###10종을 뽑을 때, 특징이 차별화가 되는 녀석들로 뽑는다.,
###10 epoch ~ 30 epoch까지 해보고, 결과가 잘나오는 구간을 찾아낸 뒤, 다시 학습할 때는 early stop을 한다.,

>##(2트) 해본 결과:
###65%였던 검증 정확도가, 90퍼센트가 됨,
###데이터 수가 적어서(50개) 인 것 같아, 실시간 변형,
###(좌우 반전, 상하좌우 움직임, 밝기 변화, 트리밍 등등)
###50개를 x 7배로 늘려서 학습진행(데이터 증강)

>##(3트): 
###데이터 증강 후 92%까지 향상,
###드롭아웃 비율을 조정하여 재도전하기로 함,
###앙상블을 위해 (3트)버전은 keep해놓기로.
